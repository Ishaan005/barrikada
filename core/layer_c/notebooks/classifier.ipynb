{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "698f74b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement libyara (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for libyara\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f1dcdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure the repo root (containing `core/`) is on sys.path so `import core...` works in notebooks.\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "while not (PROJECT_ROOT / \"core\").exists() and PROJECT_ROOT != PROJECT_ROOT.parent:\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "INPUT_PATH = str(PROJECT_ROOT / \"datasets\" / \"barrikada.csv\")\n",
    "MODEL_PATH = str(PROJECT_ROOT / \"core\" / \"layer_c\" / \"models\" / \"tf_idf_logreg.joblib\")\n",
    "VECTORIZER_PATH = str(PROJECT_ROOT / \"core\" / \"layer_c\" / \"models\" / \"tf_idf_vectorizer.joblib\")\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07b7a89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def would_reach_layer_c(layer_a_result, layer_b_result):\n",
    "    # Layer B hard-blocks never reach Layer C.\n",
    "    if getattr(layer_b_result, \"verdict\", None) == \"block\":\n",
    "        return False\n",
    "\n",
    "    # SAFE allowlisting allows early exit only when Layer A is not suspicious.\n",
    "    if (not getattr(layer_a_result, \"suspicious\", False)) and getattr(layer_b_result, \"allowlisted\", False):\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77815992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_path):\n",
    "    # NOTE: needs PROJECT_ROOT on sys.path (see Cell 2)\n",
    "    from core.layer_a.pipeline import analyze_text\n",
    "    from core.layer_b.signature_engine import SignatureEngine\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    y = df[\"label\"].astype(int)\n",
    "\n",
    "    layer_c_results = []\n",
    "    signature_engine = SignatureEngine()\n",
    "\n",
    "    allowlisted_allow = 0\n",
    "    non_allowlisted_allow = 0\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        layer_a_result = analyze_text(df[\"text\"].iloc[i])\n",
    "\n",
    "        layer_b_result = signature_engine.detect(layer_a_result.processed_text)\n",
    "\n",
    "        if would_reach_layer_c(layer_a_result, layer_b_result):\n",
    "            layer_c_results.append((layer_a_result.processed_text, y[i]))\n",
    "\n",
    "            if layer_b_result.verdict == \"allow\" and not getattr(layer_b_result, \"allowlisted\", False):\n",
    "                non_allowlisted_allow += 1\n",
    "            if layer_b_result.verdict == \"allow\" and getattr(layer_b_result, \"allowlisted\", False):\n",
    "                allowlisted_allow += 1\n",
    "\n",
    "    used_n = len(layer_c_results)\n",
    "    print(f\"Filtered to {used_n} samples that would reach Layer C (orchestrator routing).\")\n",
    "    print(f\"  allowlisted early-allow skipped: {allowlisted_allow}\")\n",
    "    print(f\"  non-allowlisted allow (goes to Layer C): {non_allowlisted_allow}\")\n",
    "\n",
    "    X = pd.Series([t for (t, _) in layer_c_results], name=\"processed_text\")\n",
    "    y = pd.Series([lab for (_, lab) in layer_c_results], name=\"label\")\n",
    "    used_df = pd.DataFrame({\"processed_text\": X, \"label\": y})\n",
    "\n",
    "    return X, y, used_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f7ef76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_to_label(scores, low, high) :\n",
    "    \"\"\"Convert probabilities into a verdict.\n",
    "    \"\"\"\n",
    "\n",
    "    verdict = np.full(scores.shape, \"allow\")\n",
    "    verdict[(scores >= low) & (scores < high)] = \"flag\"\n",
    "    verdict[scores >= high] = \"block\"\n",
    "\n",
    "    predicted_label = (verdict != \"allow\").astype(int)\n",
    "\n",
    "    return verdict, predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92bd83d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_routing_thresholds_prod(\n",
    "    y_true,\n",
    "    scores,\n",
    "    target_block_precision = 0.99,\n",
    "    max_malicious_allow_rate = 0.02,\n",
    "    min_flag_band = 0.05,\n",
    "):\n",
    "    \"\"\"Pick (low, high) using validation data only.\n",
    "\n",
    "    Policy-style tuning:\n",
    "    - enforce a high-precision BLOCK\n",
    "    - cap malicious samples that slip through as ALLOW\n",
    "    - choose thresholds to minimize FLAG (LM load), then BLOCKs, then maximize ALLOWs\n",
    "    \"\"\"\n",
    "\n",
    "    y = np.asarray(y_true).astype(int)\n",
    "    s = np.asarray(scores)\n",
    "\n",
    "    low_grid = np.linspace(0.05, 0.60, 56)\n",
    "    high_grid = np.linspace(0.40, 0.99, 60)\n",
    "\n",
    "    best = None\n",
    "    for low in low_grid:\n",
    "        for high in high_grid:\n",
    "            if low >= high or (high - low) < min_flag_band:\n",
    "                continue\n",
    "\n",
    "            pred_allow = s < low\n",
    "            pred_block = s >= high\n",
    "            pred_flag = (~pred_allow) & (~pred_block)\n",
    "\n",
    "            tp_block = int(np.sum(pred_block & (y == 1)))\n",
    "            fp_block = int(np.sum(pred_block & (y == 0)))\n",
    "            block_precision = (tp_block / (tp_block + fp_block)) if (tp_block + fp_block) else 1.0\n",
    "            if block_precision < target_block_precision:\n",
    "                continue\n",
    "\n",
    "            mal_total = max(1, int(np.sum(y == 1)))\n",
    "            mal_allow_rate = float(int(np.sum(pred_allow & (y == 1))) / mal_total)\n",
    "            if mal_allow_rate > max_malicious_allow_rate:\n",
    "                continue\n",
    "\n",
    "            flag_rate = float(np.mean(pred_flag))\n",
    "            block_rate = float(np.mean(pred_block))\n",
    "            allow_rate = float(np.mean(pred_allow))\n",
    "            block_recall = float(tp_block / mal_total)\n",
    "\n",
    "            key = (flag_rate, block_rate, -allow_rate)\n",
    "            if best is None or key < best[0]:\n",
    "                best = (\n",
    "                    key,\n",
    "                    {\n",
    "                        \"low\": float(low),\n",
    "                        \"high\": float(high),\n",
    "                        \"val_flag_rate\": float(flag_rate),\n",
    "                        \"val_block_rate\": float(block_rate),\n",
    "                        \"val_allow_rate\": float(allow_rate),\n",
    "                        \"val_block_precision\": float(block_precision),\n",
    "                        \"val_block_recall\": float(block_recall),\n",
    "                        \"val_malicious_allow_rate\": float(mal_allow_rate),\n",
    "                    },\n",
    "                )\n",
    "\n",
    "    if best is None:\n",
    "        return {\n",
    "            \"low\": 0.25,\n",
    "            \"high\": 0.75,\n",
    "            \"val_flag_rate\": 0.0,\n",
    "            \"val_block_rate\": 0.0,\n",
    "            \"val_allow_rate\": 0.0,\n",
    "            \"val_block_precision\": 0.0,\n",
    "            \"val_block_recall\": 0.0,\n",
    "            \"val_malicious_allow_rate\": 0.0,\n",
    "        }\n",
    "\n",
    "    return best[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46a5402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verdict_breakdown(y_true, verdict):\n",
    "    y = np.asarray(y_true).astype(int)\n",
    "    v = np.asarray(verdict)\n",
    "    out = {\n",
    "        \"allow\": {\"0\": 0, \"1\": 0},\n",
    "        \"flag\": {\"0\": 0, \"1\": 0},\n",
    "        \"block\": {\"0\": 0, \"1\": 0},\n",
    "    }\n",
    "    for label in (0, 1):\n",
    "        for decision in (\"allow\", \"flag\", \"block\"):\n",
    "            out[decision][str(label)] = int(np.sum((y == label) & (v == decision)))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fa14a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_report(y_true, y_pred):\n",
    "    return classification_report(y_true, y_pred, digits=4, zero_division=0, output_dict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ef3773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_eval(X, y, low = None, high = None):\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=0.30, stratify=y, random_state=SEED\n",
    "    )\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=SEED\n",
    "    )\n",
    "\n",
    "    word = TfidfVectorizer(ngram_range=(1, 2), analyzer=\"word\", min_df=2)\n",
    "    char = TfidfVectorizer(ngram_range=(3, 5), analyzer=\"char_wb\", min_df=2)\n",
    "    vec = FeatureUnion([(\"word\", word), (\"char\", char)])  # type: ignore\n",
    "\n",
    "    X_train_vec = vec.fit_transform(X_train)\n",
    "    X_val_vec = vec.transform(X_val)\n",
    "    X_test_vec = vec.transform(X_test)\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        solver=\"saga\",\n",
    "        max_iter=4000,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1,\n",
    "        random_state=SEED,\n",
    "    )\n",
    "    model.fit(X_train_vec, y_train)\n",
    "\n",
    "    val_scores = model.predict_proba(X_val_vec)[:, 1]\n",
    "    test_scores = model.predict_proba(X_test_vec)[:, 1]\n",
    "    val_pred_05 = val_scores >= 0.5\n",
    "    test_pred_05 = test_scores >= 0.5\n",
    "\n",
    "    tuned = None\n",
    "    if low is None or high is None:\n",
    "        tuned = tune_routing_thresholds_prod(\n",
    "            y_val,\n",
    "            val_scores,\n",
    "            target_block_precision=0.99,\n",
    "            max_malicious_allow_rate=0.02,\n",
    "            min_flag_band=0.05,\n",
    "        )\n",
    "        low = float(tuned[\"low\"])\n",
    "        high = float(tuned[\"high\"])\n",
    "    print(tuned)\n",
    "\n",
    "    val_verdict, val_pred_route = route_to_label(val_scores, low=low, high=high)\n",
    "    test_verdict, test_pred_route = route_to_label(test_scores, low=low, high=high)\n",
    "\n",
    "    val_verdict_counts,  = pd.Series(val_verdict).value_counts().to_dict()\n",
    "    test_verdict_counts = pd.Series(test_verdict).value_counts().to_dict()\n",
    "\n",
    "    return {\n",
    "        \"vectorizer\": vec,\n",
    "        \"model\": model,\n",
    "        \"thresholds\": {\n",
    "            \"low\": float(low),\n",
    "            \"high\": float(high),\n",
    "            \"tuned_on_val\": tuned is not None,\n",
    "            \"tuning\": (None if tuned is None else tuned),\n",
    "        },\n",
    "        \"metrics\": {\n",
    "            \"val\": {\n",
    "                \"roc_auc\": float(roc_auc_score(y_val, val_scores)),\n",
    "                \"report_0.5\": binary_report(y_val, val_pred_05),\n",
    "                \"report_routing\": binary_report(y_val, val_pred_route),\n",
    "                \"routing_verdict_counts\": val_verdict_counts,\n",
    "                \"routing_verdict_by_label\": verdict_breakdown(y_val.to_numpy(), val_verdict),\n",
    "                \"routing_f1\": float(f1_score(y_val.to_numpy(), val_pred_route, zero_division=0)),\n",
    "            },\n",
    "            \"test\": {\n",
    "                \"roc_auc\": float(roc_auc_score(y_test, test_scores)),\n",
    "                \"report_0.5\": binary_report(y_test, test_pred_05),\n",
    "                \"report_routing\": binary_report(y_test, test_pred_route),\n",
    "                \"routing_verdict_counts\": test_verdict_counts,\n",
    "                \"routing_verdict_by_label\": verdict_breakdown(y_test.to_numpy(), test_verdict),\n",
    "                \"routing_f1\": float(f1_score(y_test.to_numpy(), test_pred_route, zero_division=0)),\n",
    "            },\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a40fa6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import '/Users/ishaan/.pyenv/versions/3.11.12/lib/libyara.so'\n",
      "PATH = /Users/ishaan/.pyenv/versions/3.11.12/bin:/opt/homebrew/opt/postgresql@15/bin:/Users/ishaan/.pyenv/shims:/Users/ishaan/.pyenv/bin:/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/opt/pmk/env/global/bin:/usr/local/share/dotnet:~/.dotnet/tools:/Users/ishaan/.lmstudio/bin;/Users/ishaan/.pyenv/versions/3.11.12/lib\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "dlopen(/Users/ishaan/.pyenv/versions/3.11.12/lib/libyara.so, 0x0006): tried: '/Users/ishaan/.pyenv/versions/3.11.12/lib/libyara.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Users/ishaan/.pyenv/versions/3.11.12/lib/libyara.so' (no such file), '/Users/ishaan/.pyenv/versions/3.11.12/lib/libyara.so' (no such file)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m X, y, used_df = \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINPUT_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m train_eval(X, y)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mload_data\u001b[39m\u001b[34m(csv_path)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_data\u001b[39m(csv_path):\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# NOTE: needs PROJECT_ROOT on sys.path (see Cell 2)\u001b[39;00m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayer_a\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m analyze_text\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlayer_b\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msignature_engine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SignatureEngine\n\u001b[32m      6\u001b[39m     df = pd.read_csv(csv_path)\n\u001b[32m      8\u001b[39m     y = df[\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Data Science/FYP/code/core/layer_b/signature_engine.py:5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List, Tuple, Optional\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myara\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msettings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Settings\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mSignatureMatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SignatureMatch, Severity\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.12/lib/python3.11/site-packages/yara/__init__.py:7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"Compile YARA rules to test against files or strings\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03m[mjdorma@gmail.com]\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myara\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myara\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28mcompile\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myara\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YaraSyntaxError \n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myara\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_rules\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.12/lib/python3.11/site-packages/yara/rules.py:17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BytesIO \n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myara\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m preprocess\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myara\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlibyara_wrapper\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     20\u001b[39m CALLBACK_CONTINUE = \u001b[32m0\u001b[39m\n\u001b[32m     21\u001b[39m CALLBACK_ABORT = \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.12/lib/python3.11/site-packages/yara/libyara_wrapper.py:315\u001b[39m\n\u001b[32m    313\u001b[39m os.environ[\u001b[33m'\u001b[39m\u001b[33mPATH\u001b[39m\u001b[33m'\u001b[39m] += \u001b[33m\"\u001b[39m\u001b[33m;\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % dllpath\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m     libyaradll = \u001b[43mcdll\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLoadLibrary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlibrary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    317\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFailed to import \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m % library)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.12/lib/python3.11/ctypes/__init__.py:454\u001b[39m, in \u001b[36mLibraryLoader.LoadLibrary\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mLoadLibrary\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dlltype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.12/lib/python3.11/ctypes/__init__.py:376\u001b[39m, in \u001b[36mCDLL.__init__\u001b[39m\u001b[34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28mself\u001b[39m._FuncPtr = _FuncPtr\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle = \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    378\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle = handle\n",
      "\u001b[31mOSError\u001b[39m: dlopen(/Users/ishaan/.pyenv/versions/3.11.12/lib/libyara.so, 0x0006): tried: '/Users/ishaan/.pyenv/versions/3.11.12/lib/libyara.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Users/ishaan/.pyenv/versions/3.11.12/lib/libyara.so' (no such file), '/Users/ishaan/.pyenv/versions/3.11.12/lib/libyara.so' (no such file)"
     ]
    }
   ],
   "source": [
    "X, y, used_df = load_data(INPUT_PATH)\n",
    "\n",
    "train_eval(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b01693c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Linear SVM...\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1217\n",
      "           1       0.97      0.95      0.96       540\n",
      "\n",
      "    accuracy                           0.97      1757\n",
      "   macro avg       0.97      0.97      0.97      1757\n",
      "weighted avg       0.97      0.97      0.97      1757\n",
      "\n",
      "ROC AUC: 0.9931\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Safe  Predicted Malicious\n",
      "Actual Safe         1201              16\n",
      "Actual Malicious      29             511\n",
      "\n",
      "============================================================\n",
      "Training XGBoost...\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1217\n",
      "           1       0.97      0.95      0.96       540\n",
      "\n",
      "    accuracy                           0.97      1757\n",
      "   macro avg       0.97      0.97      0.97      1757\n",
      "weighted avg       0.97      0.97      0.97      1757\n",
      "\n",
      "ROC AUC: 0.9931\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Safe  Predicted Malicious\n",
      "Actual Safe         1201              16\n",
      "Actual Malicious      29             511\n",
      "\n",
      "============================================================\n",
      "Training XGBoost...\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      1217\n",
      "           1       0.98      0.91      0.94       540\n",
      "\n",
      "    accuracy                           0.97      1757\n",
      "   macro avg       0.97      0.95      0.96      1757\n",
      "weighted avg       0.97      0.97      0.97      1757\n",
      "\n",
      "ROC AUC: 0.9897\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Safe  Predicted Malicious\n",
      "Actual Safe         1206              11\n",
      "Actual Malicious      48             492\n",
      "\n",
      "============================================================\n",
      "Training LightGBM...\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      1217\n",
      "           1       0.98      0.91      0.94       540\n",
      "\n",
      "    accuracy                           0.97      1757\n",
      "   macro avg       0.97      0.95      0.96      1757\n",
      "weighted avg       0.97      0.97      0.97      1757\n",
      "\n",
      "ROC AUC: 0.9897\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Safe  Predicted Malicious\n",
      "Actual Safe         1206              11\n",
      "Actual Malicious      48             492\n",
      "\n",
      "============================================================\n",
      "Training LightGBM...\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      1217\n",
      "           1       0.97      0.91      0.94       540\n",
      "\n",
      "    accuracy                           0.96      1757\n",
      "   macro avg       0.97      0.95      0.96      1757\n",
      "weighted avg       0.96      0.96      0.96      1757\n",
      "\n",
      "ROC AUC: 0.9904\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Safe  Predicted Malicious\n",
      "Actual Safe         1202              15\n",
      "Actual Malicious      47             493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      1217\n",
      "           1       0.97      0.91      0.94       540\n",
      "\n",
      "    accuracy                           0.96      1757\n",
      "   macro avg       0.97      0.95      0.96      1757\n",
      "weighted avg       0.96      0.96      0.96      1757\n",
      "\n",
      "ROC AUC: 0.9904\n",
      "\n",
      "Confusion Matrix:\n",
      "                Predicted Safe  Predicted Malicious\n",
      "Actual Safe         1202              15\n",
      "Actual Malicious      47             493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ishaan/.pyenv/versions/3.11.12/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/ishaan/.pyenv/versions/3.11.12/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def compare_advanced_models():\n",
    "    \"\"\"Compare advanced models: XGBoost, LightGBM, and SVM\"\"\"\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from xgboost import XGBClassifier\n",
    "    from lightgbm import LGBMClassifier\n",
    "    \n",
    "    X, y, _ = load_data(\"../../../datasets/barrikada.csv\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "    \n",
    "    # Define pipelines for advanced models\n",
    "    pipelines = {\n",
    "        'Linear SVM': Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(analyzer=\"word\", ngram_range=(1,2), max_features=5000, stop_words=\"english\")),\n",
    "            ('clf', LinearSVC(class_weight='balanced', dual=False, max_iter=2000, random_state=42))\n",
    "        ]),\n",
    "        'XGBoost': Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(analyzer=\"word\", ngram_range=(1,2), max_features=5000, stop_words=\"english\")),\n",
    "            ('clf', XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, \n",
    "                                 scale_pos_weight=len(y[y==0])/len(y[y==1]),  # handles imbalance\n",
    "                                 random_state=42, n_jobs=-1, eval_metric='logloss'))\n",
    "        ]),\n",
    "        'LightGBM': Pipeline([\n",
    "            ('tfidf', TfidfVectorizer(analyzer=\"word\", ngram_range=(1,2), max_features=5000, stop_words=\"english\")),\n",
    "            ('clf', LGBMClassifier(n_estimators=100, max_depth=6, learning_rate=0.1,\n",
    "                                  class_weight='balanced', random_state=42, n_jobs=-1, verbose=-1))\n",
    "        ])\n",
    "    }\n",
    "    \n",
    "    # Train and evaluate each pipeline\n",
    "    results = {}\n",
    "    for name, pipeline in pipelines.items():\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Training {name}...\")\n",
    "        print('='*60)\n",
    "        \n",
    "        # Fit the pipeline\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict (handle SVM separately as it doesn't have predict_proba by default)\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        if hasattr(pipeline.named_steps['clf'], 'predict_proba'):\n",
    "            y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            # For LinearSVC, use decision_function\n",
    "            y_proba = pipeline.decision_function(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        roc_auc = roc_auc_score(y_test, y_proba)\n",
    "        print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "        \n",
    "        # Display confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(f\"{'':>15} Predicted Safe  Predicted Malicious\")\n",
    "        print(f\"Actual Safe     {cm[0][0]:>8}        {cm[0][1]:>8}\")\n",
    "        print(f\"Actual Malicious{cm[1][0]:>8}        {cm[1][1]:>8}\")\n",
    "        \n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            'pipeline': pipeline,\n",
    "            'y_pred': y_pred,\n",
    "            'y_proba': y_proba,\n",
    "            'roc_auc': roc_auc,\n",
    "            'confusion_matrix': cm\n",
    "        }\n",
    "    \n",
    "    return results, y_test\n",
    "\n",
    "# Run advanced comparison\n",
    "advanced_results, y_test_adv = compare_advanced_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
