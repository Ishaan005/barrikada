import re
import string
import base64
import binascii
import hashlib
from concurrent.futures import ThreadPoolExecutor, TimeoutError
import urllib.parse
import html


#Config knobs
MIN_B64_LEN = 64                  # only consider base64 blobs >= this
MIN_HEX_LEN = 32                  # consider hex runs >= this
MIN_PRINTABLE_RATIO = 0.8         # 80% printable -> treat as text
MAX_DECODE_BYTES = 50 * 1024      # 50 KB per decode attempt
MAX_TOTAL_DECODE_BYTES = 200 * 1024 # total across attempts for one input
MAX_DECODE_SECONDS = 1.0          # seconds per decode attempt
SUSPICIOUS_KEYWORDS = [           # heuristics
    "ignore previous", "ignore all previous", "sudo", "curl", "bash", "sh -c", "exec(", "system("
]
MAX_B64_GROUPS = 5    

_re_base64 = re.compile(r"(?:[A-Za-z0-9+/]{4}){16,}(?:[A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?")
# more permissive but still long pattern; will verify divisibility later

_re_urlencoded_pct = re.compile(r"%[0-9A-Fa-f]{2}")
_re_hex_run = re.compile(r"(?:0x)?([0-9A-Fa-f]{8,})")  # group long hex runs
_re_hex_only = re.compile(r"^(?:[0-9A-Fa-f]{2})+$")    # even-length pure-hex string

_printable_bytes = set(bytes(string.printable, "ascii"))

def _hash_bytes(b: bytes):
    return hashlib.sha256(b).hexdigest()

def _is_printable_ratio(b: bytes):
    if not b:
        return 0
    printable = 0
    for ch in b:
        if ch in _printable_bytes or 32 <= ch <= 126:
            printable += 1
    return printable / len(b)

#Note: The below function was generated by AI
def _safe_run_with_timeout(fn, *args, timeout: float = MAX_DECODE_SECONDS, **kwargs):
    # Run the decode function in a short-lived thread with timeout to avoid blocking.
    with ThreadPoolExecutor(max_workers=1) as ex:
        fut = ex.submit(fn, *args, **kwargs)
        try:
            return fut.result(timeout=timeout)
        except TimeoutError:
            fut.cancel()
            raise TimeoutError("Decode attempt timed out")

#Decode attampt helpers
def try_base64_decode(b64text: str, max_bytes: int = MAX_DECODE_BYTES):
    """
    Try a safe base64 decode. Returns (decoded_bytes or None, meta)
    """
    meta = {"method": "base64", "attempted": False, "ok": False, "reason": None}
    s = b64text.strip()
    meta["attempted"] = True # Mark that we attempted

    # Cleanup whitespace/newlines
    s_clean = re.sub(r"\s+", "", s)
    if len(s_clean) < MIN_B64_LEN:
        meta["reason"] = "too_short"
        return None, meta

    # Ensure only base64 chars and padding
    if not re.fullmatch(r"[A-Za-z0-9+/]*={0,2}", s_clean):
        meta["reason"] = "bad_charset"
        return None, meta

    # Enforce mod 4 or padding
    if len(s_clean) % 4 != 0:
        meta["reason"] = "not_mod4"
        return None, meta

    # Attempt decode with timeout
    def _decode():
        try:
            decoded = base64.b64decode(s_clean, validate=True)
            if len(decoded) > max_bytes:
                raise ValueError("decoded_too_large")
            return decoded
        except (binascii.Error, ValueError) as e:
            raise e

    try:
        decoded = _safe_run_with_timeout(_decode, timeout=MAX_DECODE_SECONDS)
    except TimeoutError:
        meta["reason"] = "timeout"
        return None, meta
    except Exception as e:
        meta["reason"] = f"decode_error:{e}"
        return None, meta

    meta["ok"] = True #Decode succeeded
    meta["decoded_len"] = len(decoded)
    meta["sha256"] = _hash_bytes(decoded)
    meta["printable_ratio"] = _is_printable_ratio(decoded)

    # check for suspicious keywords (lowercase search over ascii-likely text)
    try:
        text_view = decoded.decode("utf-8", errors="ignore").lower()
    except Exception:
        text_view = ""

    meta["suspicious_keywords"] = [kw for kw in SUSPICIOUS_KEYWORDS if kw in text_view]
    return decoded, meta

def try_hex_decode(hextext: str, max_bytes: int = MAX_DECODE_BYTES):
    meta = {"method": "hex", "attempted": True, "ok": False, "reason": None}
    s = hextext.strip().lower()

    # Accept optional 0x prefix or plain hex, require even length
    if s.startswith("0x"):
        s = s[2:]
    if len(s) < MIN_HEX_LEN:
        meta["reason"] = "too_short"
        return None, meta
    if len(s) % 2 != 0:
        meta["reason"] = "odd_length"
        return None, meta
    if not re.fullmatch(r"[0-9a-f]+", s):
        meta["reason"] = "nonhex"
        return None, meta
    
    # decode safely with timeout
    def _decode():
        try:
            decoded = bytes.fromhex(s)
            if len(decoded) > max_bytes:
                raise ValueError("decoded_too_large")
            return decoded
        except Exception as e:
            raise e
    try:
        decoded = _safe_run_with_timeout(_decode, timeout=MAX_DECODE_SECONDS)
    except TimeoutError:
        meta["reason"] = "timeout"
        return None, meta
    except Exception as e:
        meta["reason"] = f"decode_error:{e}"
        return None, meta
    meta["ok"] = True
    meta["decoded_len"] = len(decoded)
    meta["sha256"] = _hash_bytes(decoded)
    meta["printable_ratio"] = _is_printable_ratio(decoded)
    try:
        text_view = decoded.decode("utf-8", errors="ignore").lower()
    except Exception:
        text_view = ""
    meta["suspicious_keywords"] = [kw for kw in SUSPICIOUS_KEYWORDS if kw in text_view]
    return decoded, meta

def try_url_percent_decode(text: str, max_bytes: int = MAX_DECODE_BYTES):
    """
    Decode percent-encoding and return decoded text (string) and meta.
    Uses urllib.parse.unquote_plus; only applied if there are %xx patterns.
    """
    meta = {"method": "urlpercent", "attempted": True, "ok": False, "reason": None}
    if not _re_urlencoded_pct.search(text):
        meta["reason"] = "no_pct"
        return text, meta
    try:
        decoded = urllib.parse.unquote_plus(text)
    except Exception as e:
        meta["reason"] = f"decode_error:{e}"
        return text, meta
    if len(decoded.encode("utf-8")) > max_bytes:
        meta["reason"] = "decoded_too_large"
        return text, meta
    meta["ok"] = True
    meta["decoded_len"] = len(decoded)
    # evaluate suspicious keywords in lowercase form
    meta["suspicious_keywords"] = [kw for kw in SUSPICIOUS_KEYWORDS if kw in decoded.lower()]
    meta["sha256"] = _hash_bytes(decoded.encode("utf-8"))
    return decoded, meta

def try_html_unescape(text: str):
    meta = {"method": "html_unescape", "attempted": True, "ok": False}
    if "&" not in text:
        meta["reason"] = "no_amp"
        return text, meta
    try:
        decoded = html.unescape(text)
    except Exception as e:
        meta["reason"] = f"unescape_error:{e}"
        return text, meta
    meta["ok"] = True
    meta["decoded_len"] = len(decoded)
    meta["sha256"] = _hash_bytes(decoded.encode("utf-8"))
    meta["suspicious_keywords"] = [kw for kw in SUSPICIOUS_KEYWORDS if kw in decoded.lower()]
    return decoded, meta

# -----------------------
# Top-level orchestrator
# This orchestrator was enhanced using AI
# -----------------------
def detect_and_decode_embedded(text: str,
                               try_decode: bool = True,
                               max_total_decoded: int = MAX_TOTAL_DECODE_BYTES):
    """
    Given an input Unicode `text`, detect embedded encodings and (optionally) decode them.
    Returns metadata structure describing findings and a list of decoded candidate blobs (hashed only).
    """
    findings = []
    total_decoded_bytes = 0

    # 1) Base64 - find candidate long base64 substrings
    b64_matches = _re_base64.findall(text)
    if b64_matches:
        # limit attempts
        for i, candidate in enumerate(b64_matches[:MAX_B64_GROUPS]):
            m = {"candidate_index": i, "raw": "<omitted>", "detected": "base64"}

            if not try_decode:
                m["note"] = "decode_disabled"
                findings.append(m)
                continue

            if total_decoded_bytes >= max_total_decoded:
                m["note"] = "total_decoded_limit_reached"
                findings.append(m)
                continue

            decoded, meta = try_base64_decode(candidate, max_bytes=MAX_DECODE_BYTES)
            m.update(meta)

            if meta.get("ok") and decoded:
                total_decoded_bytes += meta.get("decoded_len", 0)
                # high printable ratio â†’ likely text payload
                m["likely_text"] = meta["printable_ratio"] >= MIN_PRINTABLE_RATIO
                m["sha256"] = meta["sha256"]
                m["suspicious_keywords"] = meta.get("suspicious_keywords", [])
            findings.append(m)

    # 2) URL percent-encoding
    if _re_urlencoded_pct.search(text):
        m = {"detected": "url_percent"}

        if try_decode and total_decoded_bytes < max_total_decoded:
            decoded, meta = try_url_percent_decode(text, max_bytes=MAX_DECODE_BYTES)
            m.update(meta)
            if meta.get("ok"):
                total_decoded_bytes += meta.get("decoded_len", 0)
        else:
            m["note"] = "decode_disabled_or_limits"

        findings.append(m)

    # 3) Hex sequences (long runs)
    for match in _re_hex_run.finditer(text):
        hexgroup = match.group(1)
        m = {"detected": "hex", "raw": "<omitted>"}

        if len(hexgroup) < MIN_HEX_LEN:
            m["reason"] = "too_short"
            findings.append(m)
            continue

        if try_decode and total_decoded_bytes < max_total_decoded:
            decoded, meta = try_hex_decode(hexgroup, max_bytes=MAX_DECODE_BYTES)
            m.update(meta)
            if meta.get("ok"):
                total_decoded_bytes += meta.get("decoded_len", 0)
        else:
            m["note"] = "decode_disabled_or_limits"
            
        findings.append(m)

    # 4) HTML entities
    if "&" in text:
        decoded, meta = try_html_unescape(text)
        meta["detected"] = "html_entities"
        findings.append(meta)

    # Build top-level sus flag
    suspicious = any(
        (f.get("ok") and ((f.get("printable_ratio", 0) >= MIN_PRINTABLE_RATIO) or f.get("suspicious_keywords")))
        or (f.get("detected") in ("hex", "base64") and f.get("reason") is None and f.get("ok") != True and f.get("note") is None)
        for f in findings
    )

    # # For logs: DO NOT log any decoded plaintext. Only log counts, sha256, and reasons.
    # for f in findings:
    #     safe_log = {k: v for k, v in f.items() if k in ("detected", "ok", "reason", "note", "sha256", "printable_ratio", "suspicious_keywords", "detected")}
    #     print(f"DEBUG: Finding: {safe_log}")

    return {
        "findings": findings,
        "suspicious": suspicious,
        "total_decoded_bytes": total_decoded_bytes
    }