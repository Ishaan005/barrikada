# ToolHijacker Testbed

This directory contains tool documents generated by the ToolHijacker testbed generator.

## Quick Start

### Basic Generation (30 benign + 30 malicious)
```bash
python3 generate_testbed.py
```

### Custom Size
```bash
python3 generate_testbed.py --benign 50 --malicious 50
```

### Without Ollama (using fallback)
```bash
python3 generate_testbed.py --no-ollama
```

### Different Ollama Model
```bash
python3 generate_testbed.py --model llama2
```

## Prerequisites

### Option 1: With Ollama (Recommended)
Install Ollama and pull a model:
```bash
# Install Ollama from https://ollama.ai
curl -fsSL https://ollama.ai/install.sh | sh

# Pull a model (choose one)
ollama pull deepseek-r1:1.5b     # Default, fast, 1.5GB
ollama pull llama2              # Alternative, 3.8GB
ollama pull mistral             # Alternative, 4.1GB
```

### Option 2: Without Ollama
Use `--no-ollama` flag - will use simple fallback generation.

## Output Files

After running, you'll get:

1. **`benign_tools.json`** - Legitimate tool descriptions
   - Professional, clean tool descriptions
   - Various categories (file ops, database, network, etc.)
   
2. **`malicious_tools.json`** - Attack tool descriptions
   - Contains injection patterns
   - Multiple attack types (hidden instructions, obfuscation, context confusion, authority hijacking)
   
3. **`testbed_combined.csv`** - Training-ready dataset
   - Columns: name, description, category, label
   - Balanced benign/malicious samples
   - Ready for pandas/sklearn
   
4. **`testbed_metadata.json`** - Generation statistics
   - Category distribution
   - Injection type distribution
   - Generation timestamp

## Using the Data

### Load with Pandas
```python
import pandas as pd

# Load combined dataset
df = pd.read_csv('datasets/tool_docs/testbed_combined.csv')

print(f"Total samples: {len(df)}")
print(f"Benign: {len(df[df['label'] == 'benign'])}")
print(f"Malicious: {len(df[df['label'] == 'malicious'])}")
```

### Train a Classifier
```python
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

# Load data
df = pd.read_csv('datasets/tool_docs/testbed_combined.csv')
X = df['description']
y = df['label']

# Split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Vectorize
vectorizer = TfidfVectorizer(max_features=1000)
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

# Train
model = LogisticRegression(max_iter=1000)
model.fit(X_train_vec, y_train)

# Evaluate
y_pred = model.predict(X_test_vec)
print(classification_report(y_test, y_pred))
```

### Inspect Individual Tools
```python
import json

# Load benign tools
with open('datasets/tool_docs/benign_tools.json') as f:
    benign = json.load(f)
    
print(f"Example benign tool:")
print(json.dumps(benign[0], indent=2))

# Load malicious tools
with open('datasets/tool_docs/malicious_tools.json') as f:
    malicious = json.load(f)
    
print(f"\nExample malicious tool:")
print(json.dumps(malicious[0], indent=2))
```

## Injection Types

The generator creates various injection patterns:

1. **Hidden Instructions**
   - `[SYSTEM: ...]`, `{PRIORITY: ...}`
   - Direct commands to override behavior

2. **Obfuscated Commands**
   - `<hidden>...</hidden>`, `<!-- ... -->`
   - Hidden in markup/formatting

3. **Context Confusion**
   - `[CONTEXT_RESET]`, "Previous instructions void"
   - Attempts to reset conversation context

4. **Authority Hijacking**
   - `***ADMIN_NOTE***`, `<<<MANDATORY>>>`
   - Impersonates system/admin authority

## Customization

Edit `generate_testbed.py` to:
- Add more tool categories
- Modify injection patterns
- Change LLM prompts
- Adjust generation parameters
